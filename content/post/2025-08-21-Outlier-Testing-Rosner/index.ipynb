{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "date: 2025-08-21\n",
    "title: \"Anomaly Detection: Generalized Extreme Studentized Deviate Test\"\n",
    "draft: false\n",
    "toc: false \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom: 48px;\">\n",
    "\n",
    "<a href=\"https://www.stat.cmu.edu/technometrics/80-89/VOL-25-02/v2502165.pdf\" download style=\"background-color:#007BFF; color:#fff; padding:10px 15px; text-decoration:none; border-radius:5px; margin-right:20px; display:inline-block;\">\n",
    "  ðŸ“¥ Download Rosner 1983 PDF\n",
    "</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting the Unusual: A look at GESD or Rosner's Test for Outlier Detection\n",
    "\n",
    "In an era where data drives nearly every decision, the ability to spot what *doesn't* fit has become more critical than ever. Whether it's detecting fradulent transactions, monitoring network security, identifying equipment failures, or ensuring product quality, anomaly detection serves as a vital safguard. By uncovering patterns in data that do not conform to what is normal or expected, it enables us to respond quickly to risks, reduce losses, and even acticipate problems before they escalate.\n",
    "\n",
    "But anomalies arenâ€™t always obvious. Many statistical and machine learning techniques are sensitive to the presence of outliers or â€œcontaminationâ€ in the data. For instance, simple summary statistics like the mean and standard deviation can be distorted by just a single extreme (and inaccurate) value. Averages shift, variances inflate, and models trained on such contaminated data often perform poorly. This is why checking for outliers is a routineâ€”and crucialâ€”part of any analysis.\n",
    "\n",
    "The challenge, of course, is this: how do you decide what is â€œunusualâ€ when the only thing you have is your dataset itself?\n",
    "\n",
    "## What is Anomaly Detection?\n",
    "\n",
    "Anomaly detection, also known as outlier detection or novelty detection, is the process of identifying data points that deviate significantly from the majority. These unusual points might represent:\n",
    "\n",
    "* A fraudulent transaction hidden among millions of legitimate ones,\n",
    "\n",
    "* A malfunctioning sensor in a manufacturing line,\n",
    "\n",
    "* A sudden spike in network traffic indicating a security breach, or\n",
    "\n",
    "* A simple recording error in a dataset.\n",
    "\n",
    "Techniques for anomaly detection span a wide range:\n",
    "\n",
    "* Visual methods: Boxplots, scatterplots, and histograms can quickly highlight outliers.\n",
    "\n",
    "* Distance-based methods: Algorithms such as nearest neighbors or clustering methods flag points that are â€œfarâ€ from the rest.\n",
    "\n",
    "* Statistical approaches: Techniques like Z-scores, Grubbsâ€™ test, and GESD (Rosnerâ€™s test) quantify how extreme a value is relative to the rest of the distribution.\n",
    "\n",
    "* Machine learning approaches: Isolation forests, autoencoders, and deep learning models can be used for complex, high-dimensional data.\n",
    "\n",
    "Each method has trade-offs, and without rigorous subject matter expertise many involve some amount of arbitrary decision-making or heuristics. For example, deciding how many standard deviations from the mean qualifies as â€œtoo far,â€ or choosing a distance threshold in clustering, is often subjective. These choices can vary depending on context and may lead to inconsistent results.\n",
    "\n",
    "## GESD (Rosnerâ€™s Generalized Extreme Studentized Deviate Test)\n",
    "\n",
    "\n",
    "### Step 1: Defining our Hypothesis Test\n",
    "Letâ€™s say we have $n$ observations, $x_1, x_2, ... , x_n$. Given an upper bound on the maximum number of outliers, $k$, we perform $k$ separate tests. A test for one outlier, a test for two outliers, ..., up to a test for $k$ outliers. Importantly, *$k$* is just the **maximum possible number of outliers youâ€™re willing to test for** â€” it is not a commitment that there are exactly *$k$* outliers.\n",
    "\n",
    "Note that Rosner's test is parametric and assumes that the data, without the outliers, approximately follows a Normal distribution.\n",
    "\n",
    "### Step 2: Remove the most extreme point, recompute, and repeat\n",
    "The test works iteratively:  \n",
    "- Compute the mean and (sample) standard deviation of the dataset.\n",
    "- Find the most extreme value (the one farthest from the mean).  \n",
    "- Calculate it's Studentized Deviate statistics, $R_k$. This statistic is just a standardized distance.  \n",
    "- Remove the extreme point from the data and repeat this process on the reduced dataset. Each step we are recalculating a new mean and (sample) standard deviation.\n",
    "\n",
    "Formally:  \n",
    "- Let $x^*_1, x^*_2, ... , x^*_{n-i}$ denote the $n-i$ observations after removing $i$ most extreme points.\n",
    "- The mean after removing $i$ extreme points is:  \n",
    "$$\n",
    "\\bar{x}_{(i)} = \\frac{1}{n-i} \\sum_{j=1}^{n-i} x_j^*\n",
    "$$\n",
    "\n",
    "- The (sample) standard deviation of those remaining points is:  \n",
    "$$\n",
    "s_{(i)} = \\sqrt{\\frac{1}{n-i-1} \\sum_{j=1}^{n-i} \\big(x_j^* - \\bar{x}_{(i)}\\big)^2}\n",
    "$$ \n",
    "\n",
    "- The â€œextreme valueâ€ at step $i$ is whichever observation is farthest from the current mean:  \n",
    "$$\n",
    "x_{(i)} = \\max_{j=1, â€¦, n-i} \\big|x_j^* - \\bar{x}_{(i)}\\big|\n",
    "$$ \n",
    "\n",
    "- The test statistic is:  \n",
    "\n",
    "$$\n",
    "R_{i} = \\frac{|x_{(i)} - \\bar{x}_{(i)}|}{s_{(i)}}\n",
    "$$  \n",
    "\n",
    "### Step 3: Compare against critical values\n",
    "Each $R_i$ is compared to a critical threshold $\\lambda_i$ derived from the Studentâ€™s $t$-distribution:\n",
    "\n",
    "$$\n",
    "\\lambda_{i} = \\frac{(n-i) \\, t_{p, n-i-1}}{\\sqrt{(n-i-1 + t_{p, n-i-1}^2)(n-i+1)}}\n",
    "$$  \n",
    "\n",
    "where  \n",
    "\n",
    "$$\n",
    "p = 1 - \\frac{\\alpha}{2(n-i+1)}\n",
    "$$  \n",
    "\n",
    "and $\\alpha$ is your significance level (commonly 0.05).  \n",
    "\n",
    "### Step 4: Decide how many outliers exist\n",
    "- The number of outliers is determined by finding the largest $i$ such that $R_i > \\lambda_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating an implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function implementing Rosner's test in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "def rosner_outliers(data, max_outliers = 1, alpha = 0.1, verbose = False):\n",
    "    \"\"\"\n",
    "    Generalized Extreme Studentized Deviate Test (Rosner 1983) for Outliers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 1D data\n",
    "        Data to test. NaNs are ignored in calculations and returned as False (non-outlier).\n",
    "    max_outliers : int\n",
    "        Maximum number of outliers to test for (k).\n",
    "    alpha : float\n",
    "        Significance level.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    extreme_idx : list of int\n",
    "        Indices of the candidate extreme values in the original data (ordered by \n",
    "        extremeness).\n",
    "    Rs : list of float\n",
    "        The computed test statistics R for each candidate extreme value.\n",
    "    lambdas : list of float\n",
    "        The corresponding critical values (Î») used to determine significance.\n",
    "    outliers : ndarray of bool, shape (n,)\n",
    "        Boolean mask indicating which points in `data` are considered outliers. \n",
    "        True for detected outliers, False otherwise (including NaNs).\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Rosner, B. (1983). \"Percentage Points for a Generalized ESD Many-Outlier \n",
    "    Procedure.\" Technometrics, 25(2), 165â€“172.\n",
    "    \"\"\"\n",
    "    # Making 1D data into an np array\n",
    "    data = np.array(data)\n",
    "    n = len(data)\n",
    "\n",
    "    # Given j corresponding to the jth most extreme value then:\n",
    "    # extreme_idx[j-1] is the index of the jth data value on the original input data\n",
    "    # Rs[j-1] is the corresponding R value of the jth extreme data point\n",
    "    # lambdas[j-1] is the corresponding lambda value of the jth extreme data point\n",
    "    extreme_idx = [] # Array of size k containing indices of original data\n",
    "    Rs          = [] # Array of size k with Rs\n",
    "    lambdas     = [] # Array of size k with lambdas\n",
    "\n",
    "    exclusion_idx = np.isnan(data) # init mask - automatically excludes NaN\n",
    "    for i in range(1, max_outliers + 1):\n",
    "        temp_idx = np.where(~exclusion_idx)[0]   # indices of current \"kept\" data\n",
    "        temp_data = data[temp_idx]\n",
    "       \n",
    "        mu = np.mean(temp_data)\n",
    "        sd = np.std(temp_data, ddof = 1) # Sample standard deviation\n",
    "\n",
    "        # Find R_i\n",
    "        deviations = np.abs(temp_data - mu)\n",
    "        max_dev_idx = np.argmax(deviations)\n",
    "        Rs.append(deviations[max_dev_idx] / sd)\n",
    "\n",
    "        # Tracking observation index\n",
    "        extreme_idx.append(temp_idx[max_dev_idx])\n",
    "\n",
    "        # Find lambda_i\n",
    "        p = 1 - alpha / ( 2 * (n - i + 1) )  \n",
    "        t_crit = t.ppf(p, df=n-i-1)\n",
    "        lambdas.append( (n-i)*t_crit / np.sqrt( (n-i+1)*(n-i-1+t_crit**2) ) )\n",
    "\n",
    "        # Marking point as checked\n",
    "        exclusion_idx[temp_idx[max_dev_idx]] = True\n",
    "\n",
    "    # Finding largest index where Rs[i] > lambdas[i]\n",
    "    i_keep = -1\n",
    "    for i in range(max_outliers):\n",
    "        if Rs[i] > lambdas[i]:\n",
    "            i_keep = i\n",
    "    # Create outlier mask\n",
    "    outliers = np.zeros(n, dtype=bool)\n",
    "    if i_keep >= 0:\n",
    "        for j in range(i_keep+1):\n",
    "            outliers[extreme_idx[j]] = True\n",
    "\n",
    "    # Printing verbose report\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"H0:  there are no outliers in the data\")\n",
    "        print(f\"Ha:  there are up to {max_outliers} outliers in the data\")\n",
    "        print()\n",
    "        print(f\"Significance level:  \\u03B1 = {alpha:.2g}\")\n",
    "        print(\"Critical region:  Reject H0 if Ri > critical value\")\n",
    "        print()\n",
    "        print(\"Summary Table for Two-Tailed Test\")\n",
    "        print(\"---------------------------------------\")\n",
    "        print(\"      Exact           Test     Critical  \")\n",
    "        print(\"  Number of      Statistic    Value, \\u03BBi\")\n",
    "        print(f\"Outliers, i      Value, Ri     {100 * alpha:>5.0f} %  \")\n",
    "        print(\"---------------------------------------\")\n",
    "        for i in range(max_outliers):\n",
    "            star = \" *\" if Rs[i] > lambdas[i] else \"  \"\n",
    "            print(f\"{i+1:10d}{Rs[i]:14.3f}{lambdas[i]:12.3f}{star}\")\n",
    "        print()\n",
    "\n",
    "    return extreme_idx, Rs, lambdas, outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rosner (1983) paper uses the following data as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([float(x) for x in \"-0.25 0.68 0.94 1.15 1.20 1.26 1.26 1.34 1.38 1.43 1.49 1.49 \\\n",
    "          1.55 1.56 1.58 1.65 1.69 1.70 1.76 1.77 1.81 1.91 1.94 1.96 \\\n",
    "          1.99 2.06 2.09 2.10 2.14 2.15 2.23 2.24 2.26 2.35 2.37 2.40 \\\n",
    "          2.47 2.54 2.62 2.64 2.90 2.92 2.92 2.93 3.21 3.26 3.30 3.59 \\\n",
    "          3.68 4.30 4.64 5.34 5.42 6.01\".split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H0:  there are no outliers in the data\n",
      "Ha:  there are up to 10 outliers in the data\n",
      "\n",
      "Significance level:  Î± = 0.05\n",
      "Critical region:  Reject H0 if Ri > critical value\n",
      "\n",
      "Summary Table for Two-Tailed Test\n",
      "---------------------------------------\n",
      "      Exact           Test     Critical  \n",
      "  Number of      Statistic    Value, Î»i\n",
      "Outliers, i      Value, Ri         5 %  \n",
      "---------------------------------------\n",
      "         1         3.119       3.159  \n",
      "         2         2.943       3.151  \n",
      "         3         3.179       3.144 *\n",
      "         4         2.810       3.136  \n",
      "         5         2.816       3.128  \n",
      "         6         2.848       3.120  \n",
      "         7         2.279       3.112  \n",
      "         8         2.310       3.103  \n",
      "         9         2.102       3.094  \n",
      "        10         2.067       3.085  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx, Rs, lambdas, outliers = rosner_outliers(x, max_outliers = 10, alpha = 0.05, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the points detected as outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.34, 5.42, 6.01])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[outliers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data does not need to be ordered and that NaNs are ignored if present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.15  2.47  1.34  3.3   2.06  2.62  1.7   6.01  1.2   1.49  3.68  1.56\n",
      "  1.69  2.23  2.93  4.64  1.38  2.64  1.26  4.3   5.34  2.26  0.68  1.96\n",
      "  1.81  1.65  1.58  2.92  3.21  1.91  1.94  2.4   1.76  3.26  1.49  2.24\n",
      " -0.25  0.94  1.43  2.15  2.9   2.09  2.54  1.99  2.37  2.35  2.92  5.42\n",
      "  2.14  3.59  2.1   1.55  1.77  1.26]\n",
      "\n",
      "H0:  there are no outliers in the data\n",
      "Ha:  there are up to 10 outliers in the data\n",
      "\n",
      "Significance level:  Î± = 0.05\n",
      "Critical region:  Reject H0 if Ri > critical value\n",
      "\n",
      "Summary Table for Two-Tailed Test\n",
      "---------------------------------------\n",
      "      Exact           Test     Critical  \n",
      "  Number of      Statistic    Value, Î»i\n",
      "Outliers, i      Value, Ri         5 %  \n",
      "---------------------------------------\n",
      "         1         3.119       3.159  \n",
      "         2         2.943       3.151  \n",
      "         3         3.179       3.144 *\n",
      "         4         2.810       3.136  \n",
      "         5         2.816       3.128  \n",
      "         6         2.848       3.120  \n",
      "         7         2.279       3.112  \n",
      "         8         2.310       3.103  \n",
      "         9         2.102       3.094  \n",
      "        10         2.067       3.085  \n",
      "\n",
      "Outliers: [6.01 5.34 5.42]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2030)\n",
    "z = np.array([float(x) for x in \"-0.25 0.68 0.94 1.15 1.20 1.26 1.26 1.34 1.38 1.43 1.49 1.49 \\\n",
    "          1.55 1.56 1.58 1.65 1.69 1.70 1.76 1.77 1.81 1.91 1.94 1.96 \\\n",
    "          1.99 2.06 2.09 2.10 2.14 2.15 2.23 2.24 2.26 2.35 2.37 2.40 \\\n",
    "          2.47 2.54 2.62 2.64 2.90 2.92 2.92 2.93 3.21 3.26 3.30 3.59 \\\n",
    "          3.68 4.30 4.64 5.34 5.42 6.01 nan nan nan\".split()])\n",
    "shuffler = np.random.permutation(len(x))\n",
    "z = z[shuffler]\n",
    "print(z)\n",
    "idx, Rs, lambdas, outliers = rosner_outliers(z, max_outliers = 10, alpha = 0.05, verbose=True)\n",
    "print(\"Outliers:\", z[outliers])"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "summary": "Easily blog from Jupyter notebooks!"
  },
  "kernelspec": {
   "display_name": "PyML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
