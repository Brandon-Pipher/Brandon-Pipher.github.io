{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "date: 2025-07-06\n",
    "title: \"Bank Loan Modeling: Binary Classification Demo\"\n",
    "draft: false\n",
    "toc: false \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Context\n",
    "\n",
    "This case is about a bank which has a growing customer base. \n",
    "\n",
    "Majority of these customers are liability customers (depositors) with varying size of deposits. The number of customers who are also borrowers (asset customers) is quite small, and the bank is interested in expanding this base rapidly to bring in more loan business and in the process, earn more through the interest on loans. In particular, the management wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors). A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise campaigns to better target marketing to increase the success ratio with a minimal budget.\n",
    "\n",
    "The department wants to build a model that will help them identify the potential customers who have a higher probability of purchasing the loan. This will increase the success ratio while at the same time reduce the cost of the campaign. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Variable | Description|\n",
    "|--|--|\n",
    "|ID | Customer ID |\n",
    "|Age |\tCustomer's age in completed years |\n",
    "|Experience|\t#years of professional experience |\n",
    "|Income|\tAnnual income of the customer ($000)|\n",
    "|ZIPCode|\tHome Address ZIP code.|\n",
    "|Family|\tFamily size of the customer|\n",
    "|CCAvg|\tAvg. spending on credit cards per month ($000)|\n",
    "|Education|\tEducation Level. 1: Undergrad; 2: Graduate; 3: Advanced/Professional|\n",
    "|Mortgage|\tValue of house mortgage if any. ($000)|\n",
    "|Personal Loan|\tDid this customer accept the personal loan offered in the last campaign?|\n",
    "|Securities Account|\tDoes the customer have a securities account with the bank?|\n",
    "|CD Account|\tDoes the customer have a certificate of deposit (CD) account with the bank?|\n",
    "|Online|\tDoes the customer use internet banking facilities?|\n",
    "|CreditCard|\tDoes the customer use a credit card issued by UniversalBank?|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost\n",
    "import catboost\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import duckdb as db\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "cols_categorical = {'id', 'zip code','education','personal loan', 'securities account', 'cd account', 'online', 'creditcard'}\n",
    "\n",
    "cols = pd.read_csv('Bank_Personal_Loan_Modelling.csv', nrows=0).columns\n",
    "dtypes_mapping = {col: 'category' if col.lower() in cols_categorical else 'float32' for col in cols}\n",
    "\n",
    "loans = pd.read_csv('Bank_Personal_Loan_Modelling.csv', dtype = dtypes_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data EDA Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_pct</th>\n",
       "      <th>mode</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>sample_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>category</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1, 2, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>float32</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>25.0, 45.0, 39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>float32</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0, 19.0, 15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>float32</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>49.0, 34.0, 11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIP Code</th>\n",
       "      <td>category</td>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91107, 90089, 94720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>float32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0, 3.0, 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCAvg</th>\n",
       "      <td>float32</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.6, 1.5, 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>category</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1, 2, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mortgage</th>\n",
       "      <td>float32</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0, 155.0, 104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Loan</th>\n",
       "      <td>category</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Securities Account</th>\n",
       "      <td>category</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD Account</th>\n",
       "      <td>category</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Online</th>\n",
       "      <td>category</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditCard</th>\n",
       "      <td>category</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dtype  n_unique  missing  missing_pct   mode   min  \\\n",
       "ID                  category      5000        0          0.0      1   NaN   \n",
       "Age                  float32        45        0          0.0   35.0  23.0   \n",
       "Experience           float32        47        0          0.0   32.0  -3.0   \n",
       "Income               float32       162        0          0.0   44.0   8.0   \n",
       "ZIP Code            category       467        0          0.0  94720   NaN   \n",
       "Family               float32         4        0          0.0    1.0   1.0   \n",
       "CCAvg                float32       108        0          0.0    0.3   0.0   \n",
       "Education           category         3        0          0.0      1   NaN   \n",
       "Mortgage             float32       347        0          0.0    0.0   0.0   \n",
       "Personal Loan       category         2        0          0.0      0   NaN   \n",
       "Securities Account  category         2        0          0.0      0   NaN   \n",
       "CD Account          category         2        0          0.0      0   NaN   \n",
       "Online              category         2        0          0.0      1   NaN   \n",
       "CreditCard          category         2        0          0.0      0   NaN   \n",
       "\n",
       "                    median    max        sample_unique  \n",
       "ID                     NaN    NaN              1, 2, 3  \n",
       "Age                   45.0   67.0     25.0, 45.0, 39.0  \n",
       "Experience            20.0   43.0      1.0, 19.0, 15.0  \n",
       "Income                64.0  224.0     49.0, 34.0, 11.0  \n",
       "ZIP Code               NaN    NaN  91107, 90089, 94720  \n",
       "Family                 2.0    4.0        4.0, 3.0, 1.0  \n",
       "CCAvg                  1.5   10.0        1.6, 1.5, 1.0  \n",
       "Education              NaN    NaN              1, 2, 3  \n",
       "Mortgage               0.0  635.0    0.0, 155.0, 104.0  \n",
       "Personal Loan          NaN    NaN                 0, 1  \n",
       "Securities Account     NaN    NaN                 1, 0  \n",
       "CD Account             NaN    NaN                 0, 1  \n",
       "Online                 NaN    NaN                 0, 1  \n",
       "CreditCard             NaN    NaN                 0, 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick exploratory analysis\n",
    "def quick_column_summary(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'n_unique': df.nunique(dropna=True),\n",
    "        'missing': df.isna().sum(),\n",
    "        'missing_pct': df.isna().mean() * 100,\n",
    "        'mode': df.mode(dropna=True).iloc[0]\n",
    "    })\n",
    "    return summary\n",
    "\n",
    "def quick_column_summary(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'n_unique': df.nunique(dropna=True),\n",
    "        'missing': df.isna().sum(),\n",
    "        'missing_pct': df.isna().mean() * 100,\n",
    "    })\n",
    "\n",
    "    # Compute mode safely\n",
    "    summary['mode'] = df.apply(lambda col: col.mode(dropna=True).iloc[0] if not col.mode(dropna=True).empty else np.nan)\n",
    "\n",
    "    # Add min, median, max (only for numeric columns)\n",
    "    summary['min'] = df.apply(lambda col: col.min(skipna=True) if pd.api.types.is_numeric_dtype(col) else np.nan)\n",
    "    summary['median'] = df.apply(lambda col: col.median(skipna=True) if pd.api.types.is_numeric_dtype(col) else np.nan)\n",
    "    summary['max'] = df.apply(lambda col: col.max(skipna=True) if pd.api.types.is_numeric_dtype(col) else np.nan)\n",
    "\n",
    "    # First 3 unique values as string\n",
    "    summary['sample_unique'] = df.apply(lambda col: ', '.join(map(str, col.dropna().unique()[:3])))\n",
    "\n",
    "    return summary\n",
    "\n",
    "print(\"Data EDA Summary\")\n",
    "quick_column_summary(loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a mortgage-having individual has a 'Mortgage' variable greater than zero. There is no distinction with this variable between someone owning a home outright, renting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CPU Cores / Only using CPU\n",
    "nCores = 20\n",
    "\n",
    "# Randomizer Seed\n",
    "RANDOM_STATE = 2030\n",
    "\n",
    "# Test-Train splitting data\n",
    "target = 'Personal Loan'\n",
    "\n",
    "X = loans.drop(columns=[target])\n",
    "y = loans[target].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Series to DataFrame\n",
    "df_plot = y_train.value_counts().reset_index()\n",
    "df_plot.columns = ['Purchased Person Loan', 'Frequency']\n",
    "\n",
    "# Plotting training target variable\n",
    "fig = px.bar(\n",
    "    data_frame = df_plot,\n",
    "    x = 'Purchased Person Loan',\n",
    "    y = 'Frequency',\n",
    "    title = 'Distribution of Personal Loan Purchases (y_train)',\n",
    "    template = 'plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns for preprocessing\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols   = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessor definition\n",
    "numeric_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and their parameter grids for gridsearch cv\n",
    "model_configs = {\n",
    "\n",
    "    'logistic': {\n",
    "        'model': LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000, random_state=RANDOM_STATE),\n",
    "        'params': {'model__C': [0.01, 0.1, 1, 10]}\n",
    "    },\n",
    "\n",
    "    'svc': {\n",
    "        'model': LinearSVC(penalty='l1', dual=False, max_iter=5000, random_state=RANDOM_STATE),\n",
    "        'params': {'model__C': [0.01, 0.1, 1, 10]}\n",
    "    },\n",
    "\n",
    "    'xgboost': {\n",
    "        'model': XGBClassifier(eval_metric='logloss', tree_method='hist',  random_state=RANDOM_STATE),\n",
    "        'params': {\n",
    "            'model__n_estimators': [100, 300],\n",
    "            'model__max_depth': [4, 6],\n",
    "            'model__learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'catboost': {\n",
    "        'model': CatBoostClassifier(verbose=0, task_type='CPU',  random_state=RANDOM_STATE),\n",
    "        'params': {\n",
    "            'model__iterations': [100, 300],\n",
    "            'model__depth': [4, 6],\n",
    "            'model__learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'dummy_always_zero': {\n",
    "        'model': DummyClassifier(strategy='constant', constant=0),\n",
    "        'params': {}\n",
    "    },\n",
    "\n",
    "    'dummy_always_one': {\n",
    "        'model': DummyClassifier(strategy='constant', constant=1),\n",
    "        'params': {}\n",
    "    },\n",
    "\n",
    "    'dummy_stratified': {\n",
    "        'model': DummyClassifier(strategy='stratified',  random_state=RANDOM_STATE),\n",
    "        'params': {}\n",
    "    },\n",
    "\n",
    "    'dummy_uniform': {\n",
    "        'model': DummyClassifier(strategy='uniform',  random_state=RANDOM_STATE),\n",
    "        'params': {}\n",
    "    },\n",
    "\n",
    "    'dummy_prior': {\n",
    "        'model': DummyClassifier(strategy='prior',  random_state=RANDOM_STATE),\n",
    "        'params': {}\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training logistic...\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "\n",
      "Training svc...\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "\n",
      "Training xgboost...\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "\n",
      "Training catboost...\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "\n",
      "Training dummy_always_zero...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Training dummy_always_one...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Training dummy_stratified...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Training dummy_uniform...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Training dummy_prior...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "# Implements 10-fold CV to choose best hyper parameters for each model, then uses the best parameter set for each model to predict the test set\n",
    "results = []\n",
    "\n",
    "for name, config in model_configs.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    if name == 'catboost':\n",
    "        \n",
    "        # Compute categorical column indices for CatBoost\n",
    "        cat_features_indices = [X.columns.get_loc(col) for col in categorical_cols]\n",
    "\n",
    "        # Reinitialize CatBoost with cat_features in constructor\n",
    "        model = CatBoostClassifier(verbose=0, task_type='CPU', cat_features=cat_features_indices)\n",
    "\n",
    "        # Skip encoding: passthrough raw data\n",
    "        pipe = Pipeline([\n",
    "            ('preprocess', 'passthrough'),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "        param_grid = config['params']\n",
    "\n",
    "        # Use raw X data, not transformed\n",
    "        X_train_model = X_train.copy()\n",
    "        X_test_model = X_test.copy()\n",
    "\n",
    "    else:\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            ('preprocess', preprocessor),\n",
    "            ('model', config['model'])\n",
    "        ])\n",
    "\n",
    "        param_grid = config['params']\n",
    "        X_train_model = X_train.copy()\n",
    "        X_test_model = X_test.copy()\n",
    "\n",
    "    # Grid Search\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=10, scoring='f1', n_jobs=nCores, verbose=1)\n",
    "    grid.fit(X_train_model, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # Predict\n",
    "    y_pred = best_model.predict(X_test_model)\n",
    "\n",
    "    # Compute test score\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Compute confusion matrix components\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    results.append({\n",
    "        'model': name,\n",
    "        'best_score (f1)': grid.best_score_,\n",
    "        'test_score (f1)': score,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'Specificity': tn / (tn + fp) if (tn + fp) > 0 else 0.0,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        'best_params': grid.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model  best_score (f1)  test_score (f1)  Accuracy  Precision  \\\n",
      "3           catboost         0.931500         0.917127     0.985   0.976471   \n",
      "2            xgboost         0.927703         0.928962     0.987   0.977011   \n",
      "0           logistic         0.739183         0.785276     0.965   0.955224   \n",
      "1                svc         0.736628         0.777778     0.964   0.954545   \n",
      "5   dummy_always_one         0.175180         0.175182     0.096   0.096000   \n",
      "7      dummy_uniform         0.159547         0.161074     0.500   0.096000   \n",
      "6   dummy_stratified         0.083117         0.133333     0.831   0.131313   \n",
      "4  dummy_always_zero         0.000000         0.000000     0.904   0.000000   \n",
      "8        dummy_prior         0.000000         0.000000     0.904   0.000000   \n",
      "\n",
      "     Recall  Specificity  TP   TN   FP  FN  \\\n",
      "3  0.864583     0.997788  83  902    2  13   \n",
      "2  0.885417     0.997788  85  902    2  11   \n",
      "0  0.666667     0.996681  64  901    3  32   \n",
      "1  0.656250     0.996681  63  901    3  33   \n",
      "5  1.000000     0.000000  96    0  904   0   \n",
      "7  0.500000     0.500000  48  452  452  48   \n",
      "6  0.135417     0.904867  13  818   86  83   \n",
      "4  0.000000     1.000000   0  904    0  96   \n",
      "8  0.000000     1.000000   0  904    0  96   \n",
      "\n",
      "                                         best_params  \n",
      "3  {'model__depth': 6, 'model__iterations': 300, ...  \n",
      "2  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
      "0                                   {'model__C': 10}  \n",
      "1                                    {'model__C': 1}  \n",
      "5                                                 {}  \n",
      "7                                                 {}  \n",
      "6                                                 {}  \n",
      "4                                                 {}  \n",
      "8                                                 {}  \n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values(by='best_score (f1)', ascending=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focusing on f1-score:\n",
    "\n",
    "We saw CATBOOST perform the best when training, but XGBOOST actually performed the best on the test data. The difference between their performance is due to CATBOOST making two additional false-negative predictions compared to XGBOOST."
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "summary": "Easily blog from Jupyter notebooks!"
  },
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
